{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.remove()\n",
    "logger.add(\"log.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models for vector generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load(\"data/vectors.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69982, 768)\n",
      "(29993, 768)\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(embeddings.shape[0]//3)\n",
    "\n",
    "train_idx, test_idx = train_test_split(indices, test_size=0.3, random_state=42)\n",
    "\n",
    "train_data = [embeddings[train_idx*3], embeddings[train_idx*3+1], embeddings[train_idx*3+2]]\n",
    "test_data = [embeddings[test_idx*3], embeddings[test_idx*3+1], embeddings[test_idx*3+2]]\n",
    "\n",
    "print(train_data[0].shape)\n",
    "print(test_data[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure cosine similarity differences between pos and neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(method, data, name):\n",
    "    orig_shape = data[0].shape[1]\n",
    "    pos_similarity = []\n",
    "    neg_similarity = []\n",
    "\n",
    "    queue = []\n",
    "    anchors = method(data[0])\n",
    "    positives = method(data[1])\n",
    "    negatives = method(data[2])\n",
    "   \n",
    "    for i in tqdm.trange(len(anchors)):\n",
    "        query, pos, neg = anchors[i], positives[i], negatives[i]\n",
    "        pos_similarity.append(cosine_similarity([query], [pos])[0][0])\n",
    "        neg_similarity.append(cosine_similarity([query], [neg])[0][0])\n",
    "\n",
    "    pos_similarity = np.array(pos_similarity)\n",
    "    neg_similarity = np.array(neg_similarity)\n",
    "    \n",
    "    ratio = np.sum(pos_similarity>neg_similarity)/len(pos_similarity)\n",
    "    mean_diff = pos_similarity.mean()-neg_similarity.mean()\n",
    "    mean_pos_sim = pos_similarity.mean()\n",
    "    \n",
    "    reduction_rate = orig_shape/len(anchors[0])\n",
    "    return pd.DataFrame.from_dict([{\n",
    "                        \"ratio\": ratio,\n",
    "                        \"mean_pos_sim\": mean_pos_sim,\n",
    "                        \"mean_diff\": mean_diff,\n",
    "                        \"method\": name,\n",
    "                        \"reduction_rate\": reduction_rate\n",
    "                    }])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29993/29993 [00:11<00:00, 2722.30it/s]\n"
     ]
    }
   ],
   "source": [
    "metrics.append(calculate_metrics(lambda x: x, test_data, \"CLS vector\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda_metrics = []\n",
    "# embeddings = []\n",
    "\n",
    "# train_data = data.sample(1000, random_state=42)\n",
    "\n",
    "# for i in tqdm.trange(0, train_data.shape[0], 32):\n",
    "#     embeddings.extend(embed("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 64\n",
    "\n",
    "# for idx in range(0, train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15773</th>\n",
       "      <td>what does dsm stand for</td>\n",
       "      <td>In psychology and psychiatry, DSM stands for t...</td>\n",
       "      <td>military mk, what does mark stand for in milit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35290</th>\n",
       "      <td>what is social competence in early childhood</td>\n",
       "      <td>Social competence in early childhood is as a s...</td>\n",
       "      <td>The Early Years Learning Framework (EYLF) is d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358404</th>\n",
       "      <td>stonefield construction phone number</td>\n",
       "      <td>A: The phone number for Stonefield Constructio...</td>\n",
       "      <td>The Building Official reviews applications for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381806</th>\n",
       "      <td>what book did adam smith write</td>\n",
       "      <td>Adam Smith FRSA was a Scottish economist, phil...</td>\n",
       "      <td>Was Adam Smith laissez-faire? What did it mean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244560</th>\n",
       "      <td>how long can you take naltrexone for</td>\n",
       "      <td>You and your doctor have to decide this. Most ...</td>\n",
       "      <td>Naloxone, also known as Narcan among other nam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178265</th>\n",
       "      <td>what happens in the first stage of seed germin...</td>\n",
       "      <td>Stage One - Hydration and Metabolism. In the f...</td>\n",
       "      <td>Germination is the process in which the seeds ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168368</th>\n",
       "      <td>aberdeen airport code</td>\n",
       "      <td>Aberdeen International Airport (Scottish Gaeli...</td>\n",
       "      <td>Welcome to USZip.com. USZip.com USZip.com is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314866</th>\n",
       "      <td>how old till baby can sleep on stomach</td>\n",
       "      <td>You may find yourself wondering if your baby c...</td>\n",
       "      <td>Third Month Baby Milestones: Sleep. Your 3-mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472372</th>\n",
       "      <td>what are the sisters last names in in the time...</td>\n",
       "      <td>In the Time of the Butterflies Characters. BÃ©...</td>\n",
       "      <td>The nine brightest stars of the Pleiades are n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38454</th>\n",
       "      <td>electricity cost per kwh</td>\n",
       "      <td>seattle area households paid an average of 10 ...</td>\n",
       "      <td>Â£800 per Kilowatt Average. For a large, moder...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    query  \\\n",
       "15773                             what does dsm stand for   \n",
       "35290        what is social competence in early childhood   \n",
       "358404               stonefield construction phone number   \n",
       "381806                     what book did adam smith write   \n",
       "244560               how long can you take naltrexone for   \n",
       "...                                                   ...   \n",
       "178265  what happens in the first stage of seed germin...   \n",
       "168368                              aberdeen airport code   \n",
       "314866             how old till baby can sleep on stomach   \n",
       "472372  what are the sisters last names in in the time...   \n",
       "38454                            electricity cost per kwh   \n",
       "\n",
       "                                                      pos  \\\n",
       "15773   In psychology and psychiatry, DSM stands for t...   \n",
       "35290   Social competence in early childhood is as a s...   \n",
       "358404  A: The phone number for Stonefield Constructio...   \n",
       "381806  Adam Smith FRSA was a Scottish economist, phil...   \n",
       "244560  You and your doctor have to decide this. Most ...   \n",
       "...                                                   ...   \n",
       "178265  Stage One - Hydration and Metabolism. In the f...   \n",
       "168368  Aberdeen International Airport (Scottish Gaeli...   \n",
       "314866  You may find yourself wondering if your baby c...   \n",
       "472372  In the Time of the Butterflies Characters. BÃ©...   \n",
       "38454   seattle area households paid an average of 10 ...   \n",
       "\n",
       "                                                      neg  \n",
       "15773   military mk, what does mark stand for in milit...  \n",
       "35290   The Early Years Learning Framework (EYLF) is d...  \n",
       "358404  The Building Official reviews applications for...  \n",
       "381806  Was Adam Smith laissez-faire? What did it mean...  \n",
       "244560  Naloxone, also known as Narcan among other nam...  \n",
       "...                                                   ...  \n",
       "178265  Germination is the process in which the seeds ...  \n",
       "168368  Welcome to USZip.com. USZip.com USZip.com is a...  \n",
       "314866  Third Month Baby Milestones: Sleep. Your 3-mon...  \n",
       "472372  The nine brightest stars of the Pleiades are n...  \n",
       "38454   Â£800 per Kilowatt Average. For a large, moder...  \n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_vec(dim):\n",
    "    def _inner(embeddings):\n",
    "        x = embeddings.reshape(-1, dim)\n",
    "        x = x.mean(axis=1).reshape(-1, 1)\n",
    "        x = x.reshape(len(embeddings), -1)\n",
    "        return x\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29993/29993 [00:09<00:00, 3050.61it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29993/29993 [00:10<00:00, 2987.74it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29993/29993 [00:09<00:00, 3028.07it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29993/29993 [00:09<00:00, 3039.34it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29993/29993 [00:10<00:00, 2982.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29993/29993 [00:10<00:00, 2991.96it/s]\n"
     ]
    }
   ],
   "source": [
    "for rate in [4, 8, 16, 32, 64, 128]:\n",
    "    method = average_vec(rate)\n",
    "    metrics.append(calculate_metrics(method, test_data, f\"Average parts ({rate})\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratio</th>\n",
       "      <th>mean_pos_sim</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>method</th>\n",
       "      <th>reduction_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.743273</td>\n",
       "      <td>0.705321</td>\n",
       "      <td>0.226744</td>\n",
       "      <td>Average parts (128)</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.822659</td>\n",
       "      <td>0.717699</td>\n",
       "      <td>0.233296</td>\n",
       "      <td>Average parts (64)</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.884240</td>\n",
       "      <td>0.731807</td>\n",
       "      <td>0.232372</td>\n",
       "      <td>Average parts (32)</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.922682</td>\n",
       "      <td>0.734765</td>\n",
       "      <td>0.231430</td>\n",
       "      <td>Average parts (16)</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.944587</td>\n",
       "      <td>0.732207</td>\n",
       "      <td>0.229667</td>\n",
       "      <td>Average parts (8)</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.959691</td>\n",
       "      <td>0.732543</td>\n",
       "      <td>0.229968</td>\n",
       "      <td>Average parts (4)</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.968393</td>\n",
       "      <td>0.733018</td>\n",
       "      <td>0.228607</td>\n",
       "      <td>CLS vector</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ratio  mean_pos_sim  mean_diff               method  reduction_rate\n",
       "0  0.743273      0.705321   0.226744  Average parts (128)           128.0\n",
       "0  0.822659      0.717699   0.233296   Average parts (64)            64.0\n",
       "0  0.884240      0.731807   0.232372   Average parts (32)            32.0\n",
       "0  0.922682      0.734765   0.231430   Average parts (16)            16.0\n",
       "0  0.944587      0.732207   0.229667    Average parts (8)             8.0\n",
       "0  0.959691      0.732543   0.229968    Average parts (4)             4.0\n",
       "0  0.968393      0.733018   0.228607           CLS vector             1.0"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(metrics).sort_values(\"ratio\").to_csv(\"results/benchmarks.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantize (Shelved for later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_embeddings(model, optim):\n",
    "#     batch_size = 32\n",
    "    \n",
    "#     def _inner(term):\n",
    "#         total_loss = 0\n",
    "#         embeddings = get_embeddings(term)\n",
    "#         reshaped = embeddings.view(-1, model.input_dim)\n",
    "#         _res = []\n",
    "#         for i in range(0, len(reshaped), batch_size):\n",
    "#             _batch = reshaped[i:i+batch_size]\n",
    "#             res, loss = model(_batch)\n",
    "            \n",
    "#             optim.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optim.step()\n",
    "#             _res.append(res)\n",
    "#             total_loss += loss.item()\n",
    "            \n",
    "#         res = torch.concat(_res)\n",
    "\n",
    "#         return res.view(len(embeddings), -1), total_loss\n",
    "#     return _inner\n",
    "\n",
    "# def test_embeddings(model):\n",
    "#     def _inner(term):\n",
    "#         optim.zero_grad()\n",
    "\n",
    "#         embeddings = get_embeddings(term)\n",
    "#         reshaped = embeddings.view(-1, model.input_dim)\n",
    "        \n",
    "#         res = model.reduce(reshaped)\n",
    "#         return res.view(len(embeddings), -1)\n",
    "#     return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class VectorQuantize(nn.Module):\n",
    "#     def __init__(self, input_dim, codebook_dim, codebook_size, gamma=1):\n",
    "#         super().__init__()\n",
    "#         codebook_ = torch.rand(codebook_size, codebook_dim)\n",
    "\n",
    "#         self.input_dim = input_dim\n",
    "#         self.codebook = torch.nn.Parameter(codebook_)\n",
    "#         # self.project = nn.Linear(input_dim, codebook_dim)\n",
    "#         self.project = nn.Sequential(nn.Linear(input_dim, 32),\n",
    "#                                       nn.ReLU(),\n",
    "#                                       nn.Linear(32, codebook_dim))\n",
    "#         self.expected_dist = (torch.ones(len(self.codebook))/len(self.codebook)).view(1, -1)\n",
    "#         self.gamma = gamma\n",
    "#         self.hinge_margin = torch.tensor(0)\n",
    "#         self.loss = []\n",
    "        \n",
    "#     def var_loss(self, x):\n",
    "#         var = torch.sqrt(x.var(0)+1e-6)\n",
    "#         loss = torch.maximum(self.hinge_margin, self.gamma-var).mean()\n",
    "#         return loss\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         normalized = F.normalize(x)\n",
    "#         projected = self.project(normalized)\n",
    "#         x = F.normalize(projected)\n",
    "        \n",
    "#         codes_ = F.normalize(self.codebook)\n",
    "#         dist = x@codes_.T\n",
    "#         # dist = F.softmax(dist, dim=1)\n",
    "#         # codebook_similarity_loss = F.cross_entropy(dist.mean(0).view(1, -1), self.expected_dist)\n",
    "#         codebook_similarity_loss = self.var_loss(dist)\n",
    "        \n",
    "#         dist = x@codes_.T.detach()\n",
    "#         maximum = dist.argmax(axis=1)\n",
    "#         embedding = F.embedding(maximum, self.codebook)\n",
    "#         codebook_difference_loss = F.cosine_embedding_loss(projected, embedding, torch.ones(len(x)))\n",
    "#         # codebook_difference_loss = F.cosine_embedding_loss(x, embedding, torch.ones(len(x)), 0.1)\n",
    "        \n",
    "#         variance_loss = self.var_loss(x)\n",
    "        \n",
    "#         self.loss = [codebook_difference_loss, codebook_similarity_loss, variance_loss]\n",
    "        \n",
    "#         # loss = codebook_difference_loss + codebook_similarity_loss + variance_loss\n",
    "#         loss = variance_loss\n",
    "        \n",
    "#         return x, loss\n",
    "    \n",
    "#     def reduce(self, x):\n",
    "#         normalized = F.normalize(x)\n",
    "#         return self.project(normalized).cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vec = torch.rand(1, 64)\n",
    "\n",
    "# quantizer = VectorQuantize(64, 32, 4)\n",
    "# quantizer.project.modules().__next__()[0].parameters().__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# optim = torch.optim.Adam(quantizer.parameters(), lr=3e-2)\n",
    "# _data = train_data.sample(1000)\n",
    "# for i in range(5):\n",
    "#     print(calculate_metrics(train_embeddings(quantizer, optim), _data, \"\"))\n",
    "#     print(quantizer.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec = torch.rand(3, 64)\n",
    "# projected = quantizer.reduce(vec)\n",
    "# vec, projected\n",
    "# quantizer.project.modules().__next__()[0].parameters().__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec = torch.rand(8, 16)\n",
    "# expected_dist = (torch.ones(len(quantizer.codebook))/len(quantizer.codebook)).view(1, -1)\n",
    "\n",
    "# normalized = F.normalize(vec)\n",
    "# projected = quantizer.project(normalized)\n",
    "# x = F.normalize(projected)\n",
    "\n",
    "# codes_ = F.normalize(quantizer.codebook)\n",
    "# dist = x@codes_.T\n",
    "# quantizer.var_loss(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [01:13<00:00, 135.14it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [01:14<00:00, 134.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ratio       mse  mean_diff  diff_of_means  \\\n",
      "0  0.938452  0.004588   0.054719       0.054719   \n",
      "\n",
      "                                              method  reduction_rate  \n",
      "0  Vector quantizer (16x2), normalized codebook, ...             8.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████████████████████████▋                                                                                                                          | 2493/10000 [00:18<00:55, 135.73it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_232791/800270520.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0moptim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mcalculate_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Vector quantizer ({dims[0]}x{dims[1]}), normalized codebook, fixed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_232791/3378751202.py\u001b[0m in \u001b[0;36mcalculate_metrics\u001b[0;34m(method, data, name)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_232791/2539845612.py\u001b[0m in \u001b[0;36m_inner\u001b[0;34m(term)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mreshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_232791/1789092496.py\u001b[0m in \u001b[0;36mget_embeddings\u001b[0;34m(term)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_232791/168322694.py\u001b[0m in \u001b[0;36membed\u001b[0;34m(term)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_embed2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Switching to CPU! Reason: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_232791/168322694.py\u001b[0m in \u001b[0;36m_embed2\u001b[0;34m(term, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_embed2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0msentence_rep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msentence_rep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/img_processing/lib/python3.8/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    185\u001b[0m                     \u001b[0;31m# fixes for #522 and #487 to avoid oom problems on gpu with large datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_numpy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0mall_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for dims in [(16, 2),\n",
    "#              (32, 4),\n",
    "#              (32, 2),\n",
    "#              (64, 8),\n",
    "#              (64, 4),\n",
    "#              (64, 2),\n",
    "#              (128, 16),\n",
    "#              (128, 8),\n",
    "#              (128, 4)]:\n",
    "#     quantizer = VectorQuantize(dims[0], dims[1], 64)\n",
    "#     optim = torch.optim.Adam(quantizer.parameters(), lr=3e-4)\n",
    "\n",
    "#     calculate_metrics(train_embeddings(quantizer, optim), train_data.sample(10000), \"\")\n",
    "\n",
    "#     metrics.append(calculate_metrics(test_embeddings(quantizer), test_data.sample(10000), f\"Vector quantizer ({dims[0]}x{dims[1]}), normalized codebook, fixed\"))\n",
    "#     print(metrics[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = pd.concat(metrics).groupby(\"method\").mean()\n",
    "avg[\"compression\"] = avg.index.map(lambda x: float(x.split(\"x\")[0])/float(x.split(\"x\")[1].split()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratio</th>\n",
       "      <th>mse</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>diff_of_means</th>\n",
       "      <th>compression</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32x4 (256) proper</th>\n",
       "      <td>0.93352</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.006874</td>\n",
       "      <td>0.006874</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ratio       mse  mean_diff  diff_of_means  compression\n",
       "method                                                                     \n",
       "32x4 (256) proper  0.93352  0.000079   0.006874       0.006874          8.0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg.sort_values(\"ratio\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img_processing",
   "language": "python",
   "name": "img_processing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
